{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6187ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\":50257, #词汇表大小\n",
    "    \"context_length\":256, #上下文长度\n",
    "    \"emb_dim\":768, #嵌入维度\n",
    "    \"n_heads\":12, #注意力头的数量\n",
    "    \"n_layers\":12, #层数\n",
    "    \"drop_rate\":0.1, #dropout率\n",
    "    \"qkv_bias\":False #查询-键-值偏置\n",
    "}\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out,d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,num_tokens,d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        keys = keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
    "        keys = keys.transpose(1,2)\n",
    "        queries = queries.transpose(1,2)\n",
    "        values = values.transpose(1,2)\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5,dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "        context_vec = context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"],cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            * [TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias=False\n",
    "        )\n",
    "    def forward(self,in_idx):\n",
    "        batch_size,seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x,3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),\n",
    "                          GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),\n",
    "                          GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e75f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eade4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probas = torch.softmax(logits,dim=-1)\n",
    "            idx_next = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "            idx = torch.cat((idx,idx_next),dim=1) \n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323addfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833,3626,6100],\n",
    "                       [40,1107,588]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74899b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626,6100,345],\n",
    "                        [1107,588,11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18cf2e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits,dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb14b7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "print(\"Token IDs:\\n\",token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2759894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0],tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\"{token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e04289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 1:\",target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx,[0,1,2],targets[text_idx]]\n",
    "print(\"Text 2:\",target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d63fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e194e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60535534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce8edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\",logits.shape)\n",
    "print(\"Targets shape:\",targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c9e570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\",logits_flat.shape)\n",
    "print(\"Flattened targets:\",targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "017285d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4b61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path,\"r\",encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"Tokens:\",total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2cb89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7518c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt) #对所有文本进行分词\n",
    "\n",
    "        # 使用滑动窗口将文本划分成长度为max_length的重叠序列\n",
    "        for i in range(0,len(token_ids) - max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self): # 返回数据集的总行数\n",
    "        return len(self.input_ids)\n",
    "        \n",
    "    def __getitem__(self,idx): # 返回数据集的制定行\n",
    "        return self.input_ids[idx],self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd58d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831e2b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x,y in val_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da56b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1),target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6688ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches == None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i,(input_bath,target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_bath,target_batch,model,device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee937371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48fd13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader,model,device,num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader,model,device,num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67878825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model,tokenizer,device,start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,idx=encoded,\n",
    "            max_new_tokens=50,context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\",\" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e8b5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
    "    train_losses,val_losses,track_tokens_seen = [],[],[]\n",
    "    tokens_seen,global_step = 0,-1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss,val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}):\"\n",
    "                      f\"Train loss {train_loss:.3f},\"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                      )\n",
    "        generate_and_print_sample(\n",
    "            model,tokenizer,device,start_context\n",
    "        )\n",
    "    return train_losses,val_losses,track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d140c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 9.817,Val loss 9.924\n",
      "Ep 1 (Step 000005):Train loss 7.919,Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010):Train loss 6.582,Val loss 7.035\n",
      "Ep 2 (Step 000015):Train loss 5.983,Val loss 6.588\n",
      "Every effort moves you, the, the of the, the, the, the. \", the, the,,, the, and, the, of the, the, the, the, the, the, the, and, the,, the,\n",
      "Ep 3 (Step 000020):Train loss 16.104,Val loss 16.126\n",
      "Ep 3 (Step 000025):Train loss 5.553,Val loss 6.445\n",
      "Every effort moves you. Gis. Gis. Gis. Gis. G. I had, and--, and, and, and--I. I had. I had to the his--. I had. I had been. Gis. I\n",
      "Ep 4 (Step 000030):Train loss 5.041,Val loss 6.311\n",
      "Ep 4 (Step 000035):Train loss 4.519,Val loss 6.212\n",
      "Every effort moves you, and I had been the picture--I was a--and it.          \"I to the the, I had the picture, I had the picture to the, and I had to me, I\n",
      "Ep 5 (Step 000040):Train loss 4.087,Val loss 6.216\n",
      "Every effort moves you know it was his pictures--I was his pictures--as a little of his pictures: \"--as--and it's the picture to see it was his pictures--as he was his pictures--as of his pictures--as, and in the\n",
      "Ep 6 (Step 000045):Train loss 3.417,Val loss 6.195\n",
      "Ep 6 (Step 000050):Train loss 3.089,Val loss 6.177\n",
      "Every effort moves you know; and my a little was.                            \"--and a, I, and his pictures--I was his\n",
      "Ep 7 (Step 000055):Train loss 2.670,Val loss 6.178\n",
      "Ep 7 (Step 000060):Train loss 2.030,Val loss 6.172\n",
      "Every effort moves you know; and my dear, one of the deep arm-chairs forward.                     \"--and I, the, my--and by a little his\n",
      "Ep 8 (Step 000065):Train loss 1.675,Val loss 6.219\n",
      "Ep 8 (Step 000070):Train loss 1.305,Val loss 6.170\n",
      "Every effort moves you?\" \"I that my hostess was \"interesting\": on the last word.        \"Oh, in the moment--as Jack himself, one might put it, had been the man of the hour. The\n",
      "Ep 9 (Step 000075):Train loss 1.075,Val loss 6.290\n",
      "Ep 9 (Step 000080):Train loss 0.879,Val loss 6.365\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. \"--had lent herself in an unusual degree to the display of his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085):Train loss 0.606,Val loss 6.387\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 0.0004,weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses,val_losses,tokens_seen = train_model_simple(\n",
    "    model,train_loader,val_loader,optimizer,device,\n",
    "    num_epochs=num_epochs,eval_freq=5,eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "686699c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen,tokens_seen,train_losses,val_losses):\n",
    "    fig,ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_losses,label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen,val_losses,linestyle=\"-.\",label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen,train_losses,alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a086521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e891d743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d1c6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\":0,\n",
    "    \"every\":1,\n",
    "    \"effort\":2,\n",
    "    \"forward\":3,\n",
    "    \"inches\":4,\n",
    "    \"moves\":5,\n",
    "    \"pizza\":6,\n",
    "    \"toward\":7,\n",
    "    \"you\":8,\n",
    "}\n",
    "inverse_vocab = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d908f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51,0.89,-1.90,6.75,1.63,-1.62,-1.89,6.28,1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6a43317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits,dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f054570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas,num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eca25d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas,num_samples=1).item()\n",
    "              for i in range(1_000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i,freq in enumerate(sample_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c8778ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits,temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49114049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1,0.1,5]\n",
    "scale_probas = [softmax_with_temperature(next_token_logits,T)\n",
    "                for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "for i,T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width,scale_probas[i],\n",
    "                   bar_width,label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5755760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits,top_pos = torch.topk(next_token_logits,top_k)\n",
    "print(\"Top logits:\",top_logits)\n",
    "print(\"Top positions:\",top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b587674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b34940a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits,dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af96abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,idx,max_new_tokens,context_size,temperature=0.0,top_k=None,eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:,-1,:]\n",
    "        if top_k is not None:\n",
    "            top_logits,_ = torch.topk(logits,top_k)\n",
    "            min_val = top_logits[:,-1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probas,num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx,idx_next),dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beda0f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youlit to work on surprise. It is to have been the end of enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e70a89ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bd78bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\",map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa8c85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\":model.state_dict(),\n",
    "    \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "666ab809",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\",map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=5e-4,weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "656b920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 91.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 903kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 36.8kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [18:52<00:00, 439kiB/s]    \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.57MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary URL (https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta) failed. Attempting backup URL: https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 647kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 596kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings,params = download_and_load_gpt2(\n",
    "    model_size=\"124M\",models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6bbc26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\",settings)\n",
    "print(\"Parameter dictionary keys:\",params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a129fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\",params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af9255db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\":{\"emb_dim\":768,\"n_layers\":12,\"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\":{\"emb_dim\":1024,\"n_layers\":24,\"n_heads\":16},\n",
    "    \"gpt2-large (774M)\":{\"emb_dim\":1280,\"n_layers\":36,\"n_heads\":20},\n",
    "    \"gpt2-xl (1558M)\":{\"emb_dim\":1600,\"n_layers\":48,\"n_heads\":25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7655c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c858b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\":1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32b94cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d6b1ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27b35572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left,right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         \"Right: {right.shape}\"\n",
    "                         )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d9ce4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5253e0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt,params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7758f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Haas JaguarvernmentvernmentocenerousVolcompanrepreevaitz Gap Quarterly Sectrous VR Rift vol)),veredcompaninesiana)),‎\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ballm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
